<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html;
      charset=windows-1252">
    <title>How to build quasar-based OPC-UA servers under Yocto</title>
    <style>
	div {background-color: #ddddff; width: 50%; font-family: monospace; font-size: 14; margin-bottom: 2%}

	h1 {
		counter-reset: h2counter;
	}
	h2:before {
		content: counter(h2counter) ". " ; 
		counter-increment: h2counter;
		}
    </style>
  </head>
  <body>
    <h1> Quasar + Yocto: How to (applies to PetaLinux, too)<br>
    </h1>
    <br>
    Author: Piotr Nikiel<br>
    Date: 03-Dec-2018<br>
    <br>
    <h1>Introduction</h1>
    <br>
    This rather short how-to explains how to integrate a Quasar-based
    OPC-UA server with Yocto.<br>
    <br>
    Prerequisites:<br>
    <ul>
      <li>familiarity with Quasar: creating Quasar projects, working
        with Design, attaching custom code, storing them on git.
        Experience with writing build config files for Quasar (involving
        cross-compiler toolchain) is a plus.</li>
      <li>familiarity with Yocto: building images for qemu and/or real
        hardware, deploying layers and recipes.</li>
    </ul>
    <p><br>
      The how-to presented here has been attempted in:<br>
    </p>
    <ul>
      <li>Yocto, different versions (including Rocko and Sumo),</li>
      <li>PetaLinux 2017.4, which uses Yocto behind the scenes, to build
        OPC-UA server for a PetaLinux-based project. <br>
        Note that only few points of those presented here will be of use
        for PetaLinux integration, especially the recipes will be of
        value. <br>
      </li>
    </ul>
    <ul>
    </ul>
    <h1>The terminology</h1>
    Note that I used my personal paths:<br>
    <ul>
      <li>~/gitProjects/quasar<br>
        is where I have my quasar repo (i.e. a git clone from
        https://github.com/quasar-team/quasar). I will call it <b>quasar































































          repo</b>.<br>
      </li>
      <li>~/gitProjects/poky<br>
        is where I have my reference Yocto distribution usually called
        poky (in this manual it was in the krogoth version). I cloned it
        from Yocto git repo. I will call it <b>poky repo</b>.<br>
      </li>
      <li>~/gitProjects/poky-quasar<br>
        is where I will have my Quasar-based OPC-UA server project. I
        will call it <b>project repo</b>.<br>
      </li>
    </ul>
    <h1>The procedure</h1>
    <h2>Make sure you're using the Quasar branch with Yocto support<br>
    </h2>
    <p>From quasar repo:<br>
    </p>
    <div> git checkout OPCUA-1016_yocto_quasar </div>
    <h2>Create a new Quasar project<br>
    </h2>
    From quasar repo:<br>
    <div> ./quasar.py create_project ~/gitProjects/poky-quasar </div>
    <h2>Put your new Quasar project under git version control</h2>
    <div> cd ~/gitProjects/poky-quasar <br>
      git init .<br>
      git add *<br>
      git commit -m 'Initial commit'<br>
    </div>
    <h2> Copy the reference build config from quasar repo, select it and
      store it</h2>
    From project repo:<br>
    <div>cp
      ~/gitProjects/quasar/Extra/yocto/yocto_open62541_config.cmake .<br>
      ./quasar.py set_build_config yocto_open62541_config.cmake<br>
      git add yocto_open62541_config.cmake
      FrameworkInternals/build_config_selector.cmake<br>
      git commit -a -m 'Added build config'<br>
    </div>
    <h2> Add CMake epilogue with install statements</h2>
    <br>
    We need to instruct CMake which files to install on the target. This
    can be done by copying CMakeEpilogue.cmake from us and storing it in
    your project repo:<br>
    <div>cp ~/gitProjects/quasar/Extra/yocto/CMakeEpilogue.cmake .<br>
      git add CMakeEpilogue.cmake<br>
      git commit -a -m 'Added the epilogue' </div>
    <h2>Generate CMake headers and store them</h2>
    From project repo:<br>
    <div> ./quasar.py generate cmake_headers<br>
      git add AddressSpace/cmake_generated.cmake -f<br>
      git add Device/generated/cmake_header.cmake -f<br>
      git commit -m 'Added CMake headers'<br>
    </div>
    Comment: this step is normally done behind the scenes by quasar when
    its usual entry point (quasar.py) is used rather than plain CMake. <b>That's




















      why -f (force) is used.<br>
      <br>
    </b>
    <h2>Force to use host machine JRE</h2>
    From project repo, replace value for key "java" in
    FrameworkInternals/commandMap.py to point directly to your host
    system JRE, for example for CentOS 7 or Ubuntu it would be:<br>
    <br>
    "java":"/usr/bin/java",<br>
    <br>
    Comment: we know that this bends Yocto policy a bit but at the time
    of writing (July 2018) we could not get to build OpenJDK Native in
    Yocto without GNU Classpath which seems not mature enough to run the
    Saxon XSLT processor.<br>
    <h2>Enable open62541-compat module</h2>
    From project repo:<br>
    <br>
    <div> ./quasar.py enable_module open62541-compat <font
        color="#ff0000">pnikiel-yocto-fix</font><br>
      git add FrameworkInternals/EnabledModules/open62541-compat.*<br>
      git commit -m 'Stored open62541-compat'<br>
    </div>
    <h2>Check if project builds for your host system</h2>
    <br>
    Comment: this step is not necessary per se but it will help to
    ensure that things are fine so far.<br>
    From project repo:<br>
    <div> ./quasar.py build </div>
    If you see:<br>
    [100%] Built target OpcUaServer<br>
    among the last lines of output then you're good.<br>
    <br>
    <h2>Create a branch in Yocto reference distribution for your
      developments</h2>
    Comment: you might skip this step if you are not starting from
    'ground zero'.<br>
    From poky repo:<br>
    <br>
    <div> git branch my-yocto-dev<br>
      git checkout my-yocto-dev </div>
    <br>
    <h2> Source Yocto's oe-init-build-env&nbsp;</h2>
    From poky repo:<br>
    <div> . oe-init-build-env </div>
    <h2>Build core-image-minimal (in case it's your first Yocto build)</h2>
    <p>This step will most likely cost you few hours to execute - but
      it's the one-time investment you have to take. <br>
      Yocto will pull all the dependencies and build basic things (the
      compiler, some basic OS image etc.<br>
      From poky/build dir:</p>
    <div> bitbake core-image-minimal </div>
    <h2>Create a new Yocto layer for your quasar OPC-UA server(s)</h2>
    From poky repo: <br>
    <div> bitbake-layers create-layer meta-quasar-servers<br>
      cd build<br>
      bitbake-layers add-layer ../meta-quasar-servers<br>
    </div>
    <br>
    <h2> Deploy the Yocto recipe for your OPC-UA server</h2>
    <br>
    From meta-quasar-servers which you created inside poky repo:<br>
    <div> mkdir recipes-opcua-servers<br>
      cd recipes-opcua-servers<br>
      mkdir opcua-servers<br>
      cd opcua-servers<br>
    </div>
    And copy my-opcua-server.bb from quasar repo / Extra / yocto. <br>
    This is an example recipe which you&nbsp; might base on.<br>
    <b>Note:</b> don't put underscore ( _ ) sign as a part of your
    recipe name, it serves as a delimeter between various fields of
    recipe filename. Prefer hyphens ( - ). <br>
    <br>
    <h2>Fix the path in the my-opcua-server recipe</h2>
    <br>
    The source path have to point to where your actual git repository of
    the project is (and we assumed in point 2 that it is a local one).<br>
    The variable to edit is called <b>SRC_URI</b><br>
    <br>
    <h2>Deploy xsd Yocto recipe (if not provided by anything else)</h2>
    <br>
    Out of standard Quasar dependencies, xsd is one of those not covered
    by the default layers.<br>
    If you don't provide xsd via other recipes of your system (which is
    most likely to happen when you are starting with Yocto) take the
    recipe from our repo like in the previous point.<br>
    <br>
    <h2>Deploy python-enum34 if unavailable in your Yocto/PetaLinux</h2>
    For example, PetaLinux 2017.4 provides "enum34" without "native"
    extension. You can use our recipe to provide yourself with a fix.<br>
    <br>
    <h2>Deploy pygit2 if you want to have your build stamp embedded in
      the build (and available via address-space)</h2>
    <br>
    If pygit2 is available at the OPC-UA server build time then later
    on, from the address-space as well as command line you'll be able to
    check which project commit has been used to produce the executable.<br>
    In case you don't have pygit2 via your Yocto/PetaLinux you can use
    the recipe we prepared for you in the quasar/Extra/yocto directory.<br>
    <br>
    <h2>Fix python-six if necessary</h2>
    In certain cases (e.g. PetaLinux 2017.4) we've found that python-six
    recipe (required to build open62541 0.3+ which is an "automatic"
    dependency of quasar) is broken by requiring python-io (which is an
    embedded feature of Python thus doesn't need a separate recipe).<br>
    If that is the case for you, you can copy python-six recipe from the
    SDK (Yocto/PetaLinux) to your recipes-apps, remove python-io from
    RDEPENDS and change the layer priority in order to overwrite the
    broken recipe.<br>
    The priority of a layer can be configured via layer.conf file, for
    PetaLinux this normally will be in: <br>
    <div> ./project-spec/meta-user/conf/layer.conf </div>
    <br>
    but you can generally look for it using:<br>
    <div> grep -HnRsi BBFILE_PRIORITY . </div>
    <br>
    <h2>Deploy meta-openembedded layer to get some required Python
      modules</h2>
    In poky repository:<br>
    <br>
    For Yocto sumo:<br>
    <div> git clone git://git.openembedded.org/meta-openembedded -b sumo
      --depth=1<br>
      cd build<br>
      bitbake-layers add-layer ../meta-openembedded/meta-oe<br>
      bitbake-layers add-layer ../meta-openembedded/meta-python<br>
    </div>
    For Yocto krogoth:<br>
    <div> git clone git://git.openembedded.org/meta-openembedded -b
      krogoth --depth=1<br>
      cd build<br>
      bitbake-layers add-layer ../meta-openembedded/meta-oe<br>
      bitbake-layers add-layer ../meta-openembedded/meta-python<br>
    </div>
    <h2> Add your OPC-UA server artifacts to be installed on the target
      image</h2>
    <br>
    From poky repo, edit your build/conf/local.conf and add the
    following statement in the end:<br>
    <br>
    IMAGE_INSTALL_append = " my-opcua-server"<br>
    <br>
    Note that the space character after double-quote is intentional.<br>
    <br>
    <h2>Build the minimal image</h2>
    At this stage, you could execute from poky/build directory:<br>
    <br>
    <div> bitbake core-image-minimal<br>
    </div>
    You can also build only the OPC-UA server:<br>
    <br>
    <div> bitbake my-opcua-server<br>
    </div>
    <h2>Run the minimal image in qemu</h2>
    From poky/build directory:<br>
    <br>
    <div> runqemu qemux86 core-image-minimal<br>
    </div>
    You should see your operating system bootin in qemu.<br>
    <br>
    <h2>Run the OPC-UA server</h2>
    Once you see login prompt in qemu, login as root.<br>
    Then:<br>
    <br>
    <div> cd /opt/QuasarServer<br>
      ./OpcUaServer<br>
    </div>
    <br>
    <b>Note: if you see an error that Configuration.xsd can't be found,
      just edit (vi) the config file making sure that Configuration.xsd
      has no path prefix</b>.<br>
    <br>
    <h2>Connect to the OPC-UA server using UaExpert</h2>
    <br>
    QEMU normally opens a bridge network interface between the host
    machine and the simulated target. In my case I see it when starting
    qemu (point 15) - look at the part in bold:<br>
    <br>
    /home/pnikiel/gitProjects/poky/build/tmp/sysroots/x86_64-linux/usr/bin/qemu-system-i386























    -kernel
    /home/pnikiel/gitProjects/poky/build/tmp/deploy/images/qemux86/bzImage-qemux86.bin























    -net nic,model=virtio -net
    tap,vlan=0,ifname=tap0,script=no,downscript=no -cpu qemu32 -drive
    file=/home/pnikiel/gitProjects/poky/build/tmp/deploy/images/qemux86/core-image-minimal-qemux86-20180601101954.rootfs.ext4,if=virtio,format=raw























    -show-cursor -usb -usbdevice tablet -vga vmware -no-reboot -m 256
    -serial mon:vc -serial null -append "vga=0
    uvesafb.mode_option=640x480-32 root=/dev/vda rw mem=256M ip=<b>192.168.7.2</b>::192.168.7.1:255.255.255.0























    oprofile.timer=1 rootfstype=ext4 "<br>
    <br>
    You can therefore open UaExpert and connect to the endpoint at
    192.168.7.2:4841.<br>
    <br>
    <br>
    <br>
  </body>
</html>
